We have acquired a dataset of potentially influential twitter accounts from the previous work of Rejaie \textit{et al}.  This assessment was based on connectivity, user age, and other factors.  After building our subgraph and collecting the related user attribute information, we intend to filter the subgraph based on these attributes.  We hope to be able to report on the interesting interactions between the different sets of attribute-sorted users.\\\\
Our goal will be to evaluate the nature of the connectivity of our Twitter subgraph.  We intend to discover connectivity biases amongst users of different attribute groups.  It is our belief that there is a relationship between a given user's attributes and the likelihood of that user being connected to other users of various attributes.  For a simple example, we predict that there will be a relationship between a user's location being Dallas, TX and the likelihood that other connected users are also from Dallas, TX.\\\\
To assess connectivity bias, we will group each user based on a given attribute into baskets of similar users.  There are four different forms of connectivity that must be considered -- intra-outgoing (followers within basket), intra-incoming (friends within basket), inter-outgoing (followers outside of basket) and inter-incoming (friends outside of basket).  The two intra-connectivity measurements will be assessed for each basket.  The two inter-connectivity measurerments will be assesed from each basket to every other basket.\\\\
We will then compare these results to internal and external randomly selected baskets of users.  The internal comparison will be against our main dataset.  This comparison will tell us how significant the connectivity bias for a given attribute is within our tiny Twitter universe.  The external comparison will be against another set of users that were selected randomly without regard for their influence.  This will tell us how significant the measured connectivity bias is relative to Twitter as a whole.  Using two different random distributions will also help to validate the relevance of our results to the entire Twitter network.\\\\
The above process will be repeated for as many user attributes as is prudent for the scope of our project.

\subsection{Creating Subgraphs}
After inheriting our dataset, the first step was to determine the size and nature of the Twitter subgraph that we were inspecting.  To do this, we ran a script that crawled across the entire dataset and assigned each entry a subgraph ID.  We discovered that the vast majority of dataset, 194,004 entries, were already connected.  It logically followed that the vast majority of the 17,688,493 unique user IDs in our dataset were also already contained in the primary subgraph.  As Twitter boasted 190 million users during the summer of 2010, 17.5 million represents a non-negligible amount of Twitter's active users.

\subsection{Shortcomings of Inherited Dataset}
Due to the stringent rate limits imposed by the Twitter REST API, connectivity information for our inherited dataset was truncated at 1,000 friend IDs and 1,000 follower IDs per user.  This led to our data exhibiting two unfortunate traits.  First, because connectivity data was incomplete, inconsistencies would arise in which one user's entry did not reflect the connection that was claimed by another user's entry.  Second, we were only looking at a fraction of the picture for our high degree users.  Presumably, these users would be some of the most relevant and valuable members of our graph.  After discovering that 28,669 of our user entries had been truncated at 1,000 for either their friends or followers, we took the following steps to improve our dataset.\\\\
First, we attempted to bridge together the subgraphs of our dataset.  When one user entry did not reciprocate the claimed connection of another user from a different subgraph, it was due to the connectivity truncation described above.  Whenever this occurred, we made a note of the locations at which our subgraphs were being bridged together.  We then went back and augmented the entries in the primary subgraph to include the users on the other side of the bridges.  In doing so, we were able to increase the number of users in our primary subgraph from 194,004 to XXX,XXX.\\\\
Second, we went back to the Twitter REST API to reclaim our missing connections.  We were able to obtain complete connectivity data for XX,XXX of our 28,669 truncated core users.  The remaining accounts had been disabled, suspended, or were otherwise unreachable through Twitter.  The main dataset was then augmented with the new connectivity data for our high degree users.  In addition to giving us a more accurate view of our core user's connectivity, this added X,XXX,XXX edges to our primary subgraph.\\\\
While both of these steps increased the level of information in our data, we recognize the potential inconsistencies that these measures introduced.  The most obvious is the fact that our high degree user's friends and followers were very likely to have changed between late 2010 and early 2011.  Additionally, selectively bridging the subgraphs within our dataset could potentially introduce bias in our connectivity analysis.\\\\
Despite the patchwork nature of our dataset, we feel that our findings are plausibly representative due to the nature of our analysis.  This is mostly due to the fact that we investigating connections within a subgraph, not the user nodes themselves.  For this purpose, we believe that amassing as many graph edges as possible will deliver the most meaningful results.  Additionally, the anachronisms introduced by merging multiple collection phases are only a minor concern because we do not plan to plot changes in influence over time.  There is a certain level of timelessness to the connections that are reflected in our dataset.  For example, if a follower of Ashton Kutcher's subsuently chose to stop following him, there is still information to be gleaned from that past connection.  For this reason, we were comfortable proceeding forward in spite of inconsistencies in a small minority of our data.